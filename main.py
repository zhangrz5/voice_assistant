import asyncio
import os
import time
import pygame
import speech_recognition as sr
import edge_tts
from openai import OpenAI
import pvporcupine
from pvrecorder import PvRecorder
from faster_whisper import WhisperModel

# ================= ğŸ”§ é…ç½®åŒºåŸŸ (å¿…æ”¹) =================

# 1. ä½ çš„ DeepSeek API Key
DEEPSEEK_API_KEY = "sk-36310dd6b0ba469ea7e82a3e5b57a766"

# 2. ä½ çš„ Picovoice AccessKey (æ§åˆ¶å°é¦–é¡µé‚£ä¸ª)
PICOVOICE_ACCESS_KEY = "I5CWkBsx37yttJBbKPSUtpJcZI1kZXiERkf6YgJuI3SBaCkMgjQvVA=="

# 3. ä½ çš„å”¤é†’è¯æ–‡ä»¶è·¯å¾„ (åˆšæ‰ä¸‹è½½å¹¶æ”¹åçš„æ–‡ä»¶)
# å¦‚æœæ–‡ä»¶å’Œä»£ç åœ¨åŒä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œç›´æ¥å¡«æ–‡ä»¶å
WAKE_WORD_PATH = "gouzi.ppn"

# =======================================================

# --- å…¨å±€åˆå§‹åŒ– ---

print("[*] æ­£åœ¨åŠ è½½ Faster-Whisper æ¨¡å‹ (é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½)...")
# ä½¿ç”¨ int8 é‡åŒ–åŠ é€Ÿï¼ŒCPU ä¹Ÿèƒ½é£å¿«è¿è¡Œ
try:
    stt_model = WhisperModel("small", device="cpu", compute_type="int8")
    print("[*] æ¨¡å‹åŠ è½½å®Œæˆï¼")
except Exception as e:
    print(f"[!] Whisper æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–FFmpeg: {e}")
    exit()

client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url="https://api.deepseek.com")
pygame.mixer.init()


def play_audio(file_path):
    """æ’­æ”¾éŸ³é¢‘"""
    if not os.path.exists(file_path):
        return
    try:
        pygame.mixer.music.load(file_path)
        pygame.mixer.music.play()
        while pygame.mixer.music.get_busy():
            pygame.time.Clock().tick(10)
        pygame.mixer.music.unload()
    except Exception as e:
        print(f"[!] æ’­æ”¾å‡ºé”™: {e}")


async def text_to_speech(text):
    """Edge-TTS è¯­éŸ³åˆæˆ"""
    output_file = "reply.mp3"
    # ä½¿ç”¨ä¸­æ–‡å¥³å£°ï¼šzh-CN-XiaoxiaoNeural
    try:
        communicate = edge_tts.Communicate(text, "zh-CN-XiaoxiaoNeural")
        await communicate.save(output_file)
        return output_file
    except Exception as e:
        print(f"[!] TTSç”Ÿæˆå¤±è´¥: {e}")
        return None


def call_deepseek(query):
    """DeepSeek æ€è€ƒ"""
    print(f"[*] DeepSeek æ€è€ƒä¸­: {query}")
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸­æ–‡è¯­éŸ³åŠ©æ‰‹ã€‚è¯·ç”¨ç®€çŸ­ã€å£è¯­åŒ–çš„ä¸­æ–‡å›ç­”(50å­—ä»¥å†…)ã€‚",
                },
                {"role": "user", "content": query},
            ],
            stream=False,
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"[!] APIè¯·æ±‚å¤±è´¥: {e}")
        return "æˆ‘å¥½åƒæ–­ç½‘äº†ã€‚"


def listen_and_transcribe():
    """å½•éŸ³å¹¶è¯†åˆ«"""
    r = sr.Recognizer()
    mic = sr.Microphone()
    temp_wav = "temp.wav"

    with mic as source:
        print(">> è¯·è¯´è¯ (Listening)...")
        r.adjust_for_ambient_noise(source, duration=0.5)

        try:
            # å½•éŸ³ï¼š5ç§’æ— å£°è¶…æ—¶ï¼Œæœ€é•¿å½•10ç§’
            audio = r.listen(source, timeout=5, phrase_time_limit=10)

            with open(temp_wav, "wb") as f:
                f.write(audio.get_wav_data())

            print(">> æ­£åœ¨è¯†åˆ«...")
            # ä½¿ç”¨ Faster-Whisper è¯†åˆ«ä¸­æ–‡
            segments, _ = stt_model.transcribe(temp_wav, language="zh", beam_size=5)
            text = "".join([s.text for s in segments]).strip()

            print(f">> æ”¶åˆ°: {text}")
            return text if text else None

        except sr.WaitTimeoutError:
            print("[!] æœªæ£€æµ‹åˆ°è¯­éŸ³")
            return None
        except Exception:
            return None
        finally:
            if os.path.exists(temp_wav):
                os.remove(temp_wav)


async def main():
    # 1. åŠ è½½å”¤é†’è¯
    if not os.path.exists(WAKE_WORD_PATH):
        print(f"[é”™è¯¯] æ‰¾ä¸åˆ°å”¤é†’è¯æ–‡ä»¶: {WAKE_WORD_PATH}")
        return

    try:
        porcupine = pvporcupine.create(
            access_key=PICOVOICE_ACCESS_KEY, keyword_paths=[WAKE_WORD_PATH]
        )
    except Exception as e:
        print(f"[!] å”¤é†’å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
        return

    recorder = PvRecorder(device_index=-1, frame_length=porcupine.frame_length)

    print(f"\n{'='*40}")
    print(f" ç³»ç»Ÿå°±ç»ª | è¯·è¯´å”¤é†’è¯")
    print(f"{'='*40}\n")

    try:
        recorder.start()
        while True:
            pcm = recorder.read()
            # æ£€æµ‹å”¤é†’
            if porcupine.process(pcm) >= 0:
                print(f"\n[O] å”¤é†’æˆåŠŸï¼")
                recorder.stop()

                # å¼€å§‹äº¤äº’
                user_text = listen_and_transcribe()
                if user_text:
                    reply = call_deepseek(user_text)
                    print(f"[A] AI: {reply}")

                    audio = await text_to_speech(reply)
                    if audio:
                        play_audio(audio)
                        os.remove(audio)

                print("[*] ç­‰å¾…å”¤é†’...")
                recorder.start()

    except KeyboardInterrupt:
        print("é€€å‡ºã€‚")
    finally:
        recorder.delete()
        porcupine.delete()


if __name__ == "__main__":
    if os.name == "nt":
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    asyncio.run(main())
